import streamlit as st
from pathlib import Path
import json, datetime, io, zipfile, re, unicodedata
from typing import Any, Dict

try:
    import pandas as pd
except Exception:
    pd = None

from docx import Document

st.set_page_config(page_title="Nova Letters â€” Batch Builder", layout="wide")

HERE = Path(__file__).parent
RUNTIME = HERE / "runtime"
RUNTIME.mkdir(exist_ok=True)
TEMPLATES_DIR = HERE / "templates"
DEFAULT_TEMPLATE = TEMPLATES_DIR / "default.docx"
REPO_MAPPING = HERE / "store_mapping.json"

# ---------- Helpers ----------
def format_percent(x: Any) -> str:
    try:
        val = float(x)
    except Exception:
        return str(x)
    if val < 1:
        return f"{val*100:.0f}%"
    if val < 10:
        return f"{val*100:.0f}%"
    return f"{val:.0f}%"

def replace_all(doc: Document, mapping: Dict[str, Any]) -> None:
    def repl_text(text: str) -> str:
        out = text
        for k, v in mapping.items():
            out = out.replace(f"[[{k}]]", str(v))
        return out

    for p in doc.paragraphs:
        p.text = repl_text(p.text)
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                cell.text = repl_text(cell.text)

def load_store_mapping(path: Path) -> Dict[str, Any]:
    with path.open("r", encoding="utf-8") as f:
        return json.load(f)

def build_placeholder_map(store_code: str, store_name: str, payload: Dict[str, Any]) -> Dict[str, Any]:
    today = datetime.date.today()
    out = {
        "store_code": store_code,
        "store_name": store_name,
        "month_name": today.strftime("%B"),
        "year": today.year,
        "comment": payload.get("comment", ""),
        "fixed_target": payload.get("fixed_target", ""),
        "fixed_actual": payload.get("fixed_actual", ""),
        "ftth_actual": payload.get("ftth_actual", ""),
        "eon_tv_actual": payload.get("eon_tv_actual", ""),
        "mobile_upgrades": payload.get("mobile_upgrades", ""),
        "pending_mobile": payload.get("pending_mobile", ""),
        "voice_vs_target_pct": format_percent(payload.get("voice_vs_target", "")),
    }
    # Î Î­ÏÎ½Î± ÎºÎ±Î¹ ÏŒÎ»Î± Ï„Î± Ï…Ï€ÏŒÎ»Î¿Î¹Ï€Î± columns Ï‰Ï‚ [[column_name]]
    for k, v in payload.items():
        if k not in out:
            out[k] = v
    return out

def pick_template_path(template_name: str,
                       category: str | None,
                       uploaded_template: Path | None,
                       tpl_bex: Path | None,
                       tpl_nonbex: Path | None) -> Path:
    # 1) Global uploaded template Î³Î¹Î± ÏŒÎ»Î¿Ï…Ï‚
    if uploaded_template and uploaded_template.exists():
        return uploaded_template
    # 2) Category templates
    cat = (category or "NON_BEX").upper()
    if cat == "BEX" and tpl_bex and tpl_bex.exists():
        return tpl_bex
    if cat != "BEX" and tpl_nonbex and tpl_nonbex.exists():
        return tpl_nonbex
    # 3) Per-store template Î±Ï€ÏŒ mapping (ÏƒÏ„Î¿ templates/)
    cand = TEMPLATES_DIR / (template_name or "default.docx")
    if cand.exists():
        return cand
    # 4) Fallback
    return DEFAULT_TEMPLATE

def _norm_header(s: str) -> str:
    """normalize headers: remove accents/greek, lowercase, underscores"""
    s = unicodedata.normalize('NFKD', str(s)).encode('ascii', 'ignore').decode('ascii')
    s = s.strip().lower()
    s = re.sub(r'[^a-z0-9]+', '_', s)
    return s.strip('_')

# ---------- UI ----------
st.title("ğŸ“„ Nova Letters â€” ÎœÎ±Î¶Î¹ÎºÎ® Î Î±ÏÎ±Î³Ï‰Î³Î® (BEX / NON-BEX)")

# Mapping & Template
st.subheader("1) Mapping & Template")

# (Î ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÎ¬) Î¾ÎµÏ‡Ï‰ÏÎ¹ÏƒÏ„Î¬ templates Î±Î½Î¬ ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯Î±
st.markdown("**(Î ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÎ¬) ÎÎµÏ‡Ï‰ÏÎ¹ÏƒÏ„Î¬ templates Î±Î½Î¬ ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯Î±**")
tpl_bex_up = st.file_uploader("Upload BEX template (.docx)", type=["docx"], key="tpl_bex")
tpl_nonbex_up = st.file_uploader("Upload NON-BEX template (.docx)", type=["docx"], key="tpl_nonbex")

tpl_bex_path = None
tpl_nonbex_path = None
if tpl_bex_up:
    (RUNTIME / "bex_template.docx").write_bytes(tpl_bex_up.getvalue())
    tpl_bex_path = RUNTIME / "bex_template.docx"
    st.success("âœ” BEX template uploaded.")
if tpl_nonbex_up:
    (RUNTIME / "nonbex_template.docx").write_bytes(tpl_nonbex_up.getvalue())
    tpl_nonbex_path = RUNTIME / "nonbex_template.docx"
    st.success("âœ” NON-BEX template uploaded.")

c1, c2 = st.columns(2)

with c1:
    st.markdown("**store_mapping.json** (repo Î® Î±Î½Î­Î²Î±ÏƒÎ­ Ï„Î¿)")
    m_up = st.file_uploader("Upload store_mapping.json", type=["json"])
    if m_up:
        (RUNTIME / "store_mapping.json").write_bytes(m_up.getvalue())
        st.success("Uploaded to runtime/store_mapping.json")
    if (RUNTIME / "store_mapping.json").exists():
        mapping_path = RUNTIME / "store_mapping.json"
        st.info("Using uploaded mapping (runtime).")
    elif REPO_MAPPING.exists():
        mapping_path = REPO_MAPPING
        st.info("Using mapping from repo.")
    else:
        mapping_path = None
        st.error("Missing store_mapping.json")

with c2:
    st.markdown("**Default template (.docx)** (repo Î® Î±Î½Î­Î²Î±ÏƒÎ­ Ï„Î¿)")
    t_up = st.file_uploader("Upload default template .docx", type=["docx"])
    uploaded_template = None
    if t_up:
        (RUNTIME / "custom_template.docx").write_bytes(t_up.getvalue())
        uploaded_template = RUNTIME / "custom_template.docx"
        st.success("Uploaded to runtime/custom_template.docx")
    if DEFAULT_TEMPLATE.exists():
        st.info("Repo default: templates/default.docx")

# Î”ÎµÎ´Î¿Î¼Î­Î½Î± (Excel)
st.subheader("2) Î”ÎµÎ´Î¿Î¼Î­Î½Î± â€” Excel (1 Î³ÏÎ±Î¼Î¼Î® Î±Î½Î¬ ÎºÎ±Ï„Î¬ÏƒÏ„Î·Î¼Î±)")
if pd is None:
    st.error("Î›ÎµÎ¯Ï€ÎµÎ¹ pandas/openpyxl. Î ÏÏŒÏƒÎ¸ÎµÏƒÎµ ÏƒÏ„Î¿ requirements.txt: pandas, openpyxl")
    st.stop()

excel = st.file_uploader("Upload Excel", type=["xlsx", "xls"])
sheet = st.text_input("Sheet (optional)", value="")
df = None
if excel is not None:
    try:
        df = pd.read_excel(excel, sheet_name=sheet or 0)

        # --- Normalize headers & aliasing ÏÏƒÏ„Îµ Î½Î± Î²ÏÎ¯ÏƒÎºÎ¿Ï…Î¼Îµ Ï€Î¬Î½Ï„Î± Ï„Î¿ store_code ---
        orig_cols = list(df.columns)
        df.columns = [_norm_header(c) for c in df.columns]

        aliases = {
            "store": "store_code",
            "storeid": "store_code",
            "store_id": "store_code",
            "code": "store_code",
            "dealer": "store_code",
            "dealerid": "store_code",
            "dealer_id": "store_code",
            "dealercode": "store_code",
            "dealer_code": "store_code",
            "dealer_code_id": "store_code",
            "dealer_code_number": "store_code",
            "dealercodeid": "store_code",
        }
        if "store_code" not in df.columns:
            for k, v in aliases.items():
                if k in df.columns:
                    df.rename(columns={k: v}, inplace=True)
                    break

        st.caption(f"Headers (original): {orig_cols}")
        st.caption(f"Headers (normalized): {list(df.columns)}")

        st.success(f"Î¦Î¿ÏÏ„ÏÎ¸Î·ÎºÎ±Î½ {len(df)} Î³ÏÎ±Î¼Î¼Î­Ï‚ Î±Ï€ÏŒ Excel.")
        st.write("**Preview Ï„Ï‰Î½ values Ï€Î¿Ï… Î¸Î± Ï€ÎµÏÎ¬ÏƒÎ¿Ï…Î½:**")
        st.dataframe(df, use_container_width=True)
    except Exception as e:
        st.error(f"Î£Ï†Î¬Î»Î¼Î± Î±Î½Î¬Î³Î½Ï‰ÏƒÎ·Ï‚ Excel: {e}")

# Î Î±ÏÎ±Î³Ï‰Î³Î®
st.subheader("3) Î Î±ÏÎ±Î³Ï‰Î³Î® Î±Î½Î¬ ÎºÎ±Ï„Î¬ÏƒÏ„Î·Î¼Î± & Î¿Î¼Î±Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ·")
start = st.button("ğŸš€ Generate BEX / NON-BEX & ÎºÎ±Ï„Î­Î²Î±ÏƒÎ­ Ï„Î± ÏƒÎµ ZIP")

if start:
    if mapping_path is None:
        st.error("Î›ÎµÎ¯Ï€ÎµÎ¹ store_mapping.json")
        st.stop()
    if df is None or df.empty:
        st.error("Î›ÎµÎ¯Ï€Î¿Ï…Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Excel.")
        st.stop()

    try:
        store_map = load_store_mapping(mapping_path)
    except Exception as e:
        st.error(f"Î”ÎµÎ½ Î´Î¹Î±Î²Î¬Î¶ÎµÏ„Î±Î¹ Ï„Î¿ mapping: {e}")
        st.stop()

    # In-memory zip
    mem_zip = io.BytesIO()
    zf = zipfile.ZipFile(mem_zip, mode="w", compression=zipfile.ZIP_DEFLATED)

    generated = []
    errors = []

    for idx, row in df.iterrows():
        row_dict = {k: ("" if (pd.isna(v) if pd is not None else v is None) else v) for k, v in row.to_dict().items()}

        store_code = str(row_dict.get("store_code", "")).strip()
        if not store_code:
            errors.append((idx, "Missing store_code"))
            continue

        info = store_map.get(store_code, store_map.get("_default", {}))
        store_name = info.get("store_name", store_code)
        template_name = info.get("template", "default.docx")
        category = info.get("category", "NON_BEX")

        # Î‘Î½ Ï„Î¿ Excel Î­Ï‡ÎµÎ¹ ÏƒÏ„Î®Î»Î· category, Ï€ÏÎ¿Î­Ï‡ÎµÎ¹
        if "category" in row_dict and str(row_dict["category"]).strip():
            category = str(row_dict["category"]).strip()

        # Î•Ï€Î¹Î»Î¿Î³Î® template (global uploaded / per-category / per-store / default)
        t_path = pick_template_path(template_name, category, uploaded_template, tpl_bex_path, tpl_nonbex_path)
        if not t_path or not t_path.exists():
            errors.append((store_code, f"Template not found: {t_path}"))
            continue

        placeholders = build_placeholder_map(store_code, store_name, row_dict)

        try:
            doc = Document(str(t_path))
            replace_all(doc, placeholders)

            subdir = "BEX" if str(category).upper() == "BEX" else "NON_BEX"
            out_name = f"{subdir}/Letter_{store_code}.docx"
            buf = io.BytesIO()
            doc.save(buf)
            buf.seek(0)
            zf.writestr(out_name, buf.read())
            generated.append(out_name)
        except Exception as e:
            errors.append((store_code, str(e)))

    zf.close()
    mem_zip.seek(0)

    if generated:
        st.success(f"Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎ±Î½ {len(generated)} Î±ÏÏ‡ÎµÎ¯Î±.")
        st.download_button(
            "â¬‡ï¸ ÎšÎ±Ï„Î­Î²Î±ÏƒÎµ ZIP (BEX/NON-BEX)",
            data=mem_zip,
            file_name="Nova_Letters_BEX_NONBEX.zip",
            mime="application/zip",
        )
        with st.expander("Î”ÎµÎ¯Ï„Îµ Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± Ï€Î¿Ï… Ï€ÎµÏÎ¹Î­Ï‡Î¿Î½Ï„Î±Î¹"):
            st.write("\n".join(generated))
    if errors:
        st.error("ÎšÎ¬Ï€Î¿Î¹Î± stores Î´ÎµÎ½ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎ±Î½:")
        for e in errors:
            st.write("â€¢", e)
