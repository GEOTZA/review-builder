import streamlit as st
import re, os, io, json, zipfile
from typing import Dict, Any, List, Tuple
from docx import Document
from docx.oxml.ns import qn

# PDF text extraction
try:
    from pdfminer.high_level import extract_text
except Exception:
    extract_text = None

st.set_page_config(page_title="Review/Plan Generator", layout="wide")

# ---------- helpers ----------
def set_default_font(doc, font_name="Aptos"):
    for style in doc.styles:
        if hasattr(style, "font"):
            try:
                style.font.name = font_name
                style._element.rPr.rFonts.set(qn('w:eastAsia'), font_name)
                style._element.rPr.rFonts.set(qn('w:cs'), font_name)
            except Exception:
                pass

def read_pdf_text_from_bytes(file_bytes: bytes) -> str:
    """Return extracted text or empty string; never raises to the UI."""
    if extract_text is None:
        return ""
    try:
        bio = io.BytesIO(file_bytes)
        txt = extract_text(bio) or ""
        return txt
    except Exception:
        return ""

def parse_metrics(text: str, patterns: Dict[str, str]) -> Dict[str, Any]:
    """
    Extract values using regex patterns; robust to errors.
    Keeps values as strings (no forced float cast).
    """
    results: Dict[str, Any] = {}
    for key, pat in patterns.items():
        try:
            m = re.search(pat, text, re.IGNORECASE | re.MULTILINE | re.DOTALL)
        except re.error as e:
            results[key] = f"[Regex error: {e}]"
            continue
        if m:
            try:
                # prefer last capturing group if multiple
                val = (m.group(m.lastindex) if m.lastindex else m.group(1))
            except Exception:
                val = m.group(0)
            val = (val or "").strip()
            val = val.replace(",", ".")
            results[key] = val
        else:
            results[key] = ""
    return results

def replace_placeholders(doc: Document, mapping: Dict[str, Any]):
    def repl_text(s: str) -> str:
        def rfun(m):
            k = m.group(1)
            return str(mapping.get(k, ""))
        return re.sub(r"\[\[([A-Za-z0-9_]+)\]\]", rfun, s)

    for p in doc.paragraphs:
        for r in p.runs:
            r.text = repl_text(r.text)
    for t in doc.tables:
        for row in t.rows:
            for cell in row.cells:
                for p in cell.paragraphs:
                    for r in p.runs:
                        r.text = repl_text(r.text)

def parse_file_role(name: str):
    """
    Î§Î±Î»Î±ÏÎ® Î±Î½Î±Î³Î½ÏÏÎ¹ÏƒÎ· STORE + ÏÏŒÎ»Î¿Ï… (review/plan) Î±Ï€ÏŒ filename.
    Î”Î­Ï‡ÎµÏ„Î±Î¹:
      <STORE>_Business Review.pdf
      <STORE>_Action Plan.pdf
      <STORE>-Business-Review.pdf
      <STORE> BusinessReview.pdf
      <STORE>_review.pdf
      <STORE>_plan.pdf
      <STORE>_ActionPlan.pdf
      <STORE>_BusinessReview.pdf
    """
    base = name.strip()
    if base.lower().endswith(".pdf"):
        base = base[:-4]
    # ÏƒÏ…Î¼Ï€ÏÎºÎ½Ï‰ÏƒÎµ Ï€Î¿Î»Î»Î±Ï€Î»Î¬ ÎºÎµÎ½Î¬
    base = re.sub(r"\s+", " ", base)

    # Î Î¬ÏÎµ Ï„Î¿ STORE Ï‰Ï‚ Ï€ÏÏÏ„Î¿ ÎºÎ¿Î¼Î¼Î¬Ï„Î¹
    m_store = re.match(r"^\s*([A-Za-z0-9]+)[\s_\-]+(.+)$", base)
    if not m_store:
        only_code = re.match(r"^\s*([A-Za-z0-9]+)\s*$", base)
        if only_code:
            return only_code.group(1).upper(), None
        return None, None
    store = m_store.group(1).upper()
    tail = m_store.group(2).strip().lower()

    # compact Î³Î¹Î± ÎµÏÎºÎ¿Î»Î± matches
    compact = re.sub(r"[\s_\-]+", "", tail)

    # review keys
    review_keys = ["businessreview", "review"]
    # plan keys
    plan_keys = ["actionplan", "plan"]

    if any(k in compact for k in review_keys) or tail.endswith("review"):
        return store, "review"
    if any(k in compact for k in plan_keys) or tail.endswith("plan"):
        return store, "plan"

    # fallback
    if "review" in compact:
        return store, "review"
    if "plan" in compact:
        return store, "plan"
    return store, None

# ---------- UI ----------
st.title("ğŸ“„ Review/Plan Generator (BEX & Non-BEX)")

with st.sidebar:
    st.header("âš™ï¸ Settings")
    st.caption("ÎŸÏÎ¯ÏƒÎµ BEX Î»Î¯ÏƒÏ„Î± & regex extraction (JSON).")
    bex_input = st.text_area("BEX stores (comma-separated)", "ESC01,FKM01,LND01,DRZ01,PKK01")
    bex_set = set([s.strip().upper() for s in bex_input.split(",") if s.strip()])

    default_review_patterns = {
        "mobile_actual": r"ÎšÎ¹Î½Î·Ï„(Î®|Î·Ï‚).*?(\d+)\s*(ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚|Î³ÏÎ±Î¼Î¼Î­Ï‚)",
        "fixed_actual":  r"Î£Ï„Î±Î¸ÎµÏ(Î®|Î®Ï‚).*?(\d+)\s*(ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚|Î³ÏÎ±Î¼Î¼Î­Ï‚)",
        "ftth_actual":   r"FTTH.*?(\d+)",
        "fwa_actual":    r"FWA.*?(\d+)",
        "eon_actual":    r"(EON|TV).*?(\d+)",
        # Î¼Ï€Î¿ÏÎµÎ¯Ï‚ Î½Î± Ï€ÏÎ¿ÏƒÎ¸Î­ÏƒÎµÎ¹Ï‚ ÎºÎ¹ Î¬Î»Î»Î±, Ï€.Ï‡. pending:
        # "pending_mobile": r"pending.*?ÎºÎ¹Î½Î·Ï„.*?(\d+)"
    }
    default_plan_patterns = {
        "mobile_target": r"(?i)ÎºÎ¹Î½Î·Ï„[Î®Î®Ï‚].*?(\d+)\s*(?:Î³Ï|lines|Î³ÏÎ±Ï†|ÎµÎ½ÎµÏÎ³)",
        "fixed_target":  r"(?i)ÏƒÏ„Î±Î¸ÎµÏ[Î®Î®Ï‚].*?(\d+)\s*(?:Î³Ï|lines|Î³ÏÎ±Ï†|ÎµÎ½ÎµÏÎ³)",
        "ftth_target":   r"(?i)ftth.*?(\d+)",
        "fwa_target":    r"(?i)fwa.*?(\d+)",
        "eon_target":    r"(?i)(eon|tv).*?(\d+)"
    }
    review_patterns_json = st.text_area("Review regex (JSON)", json.dumps(default_review_patterns, ensure_ascii=False, indent=2))
    plan_patterns_json   = st.text_area("Plan regex (JSON)", json.dumps(default_plan_patterns, ensure_ascii=False, indent=2))
    try:
        review_patterns = json.loads(review_patterns_json)
        plan_patterns = json.loads(plan_patterns_json)
    except Exception as e:
        st.error(f"JSON error: {e}")
        st.stop()

    st.subheader("ğŸ“„ Templates (.docx)")
    tpl_bex = st.file_uploader("BEX template", type=["docx"], key="tpl_bex")
    tpl_nonbex = st.file_uploader("Non-BEX template", type=["docx"], key="tpl_nonbex")
    st.caption("Placeholders: [[review_mobile_actual]], [[plan_mobile_target]], [[title]], [[store]], Îº.Î»Ï€.")

st.markdown("### 1) Î‘Î½Î­Î²Î±ÏƒÎµ PDFs")
st.caption("Î”ÎµÎºÏ„Î­Ï‚ Î¿Î½Î¿Î¼Î±ÏƒÎ¯ÎµÏ‚ (Ï‡Î±Î»Î±ÏÏŒ matching): <STORE>_Business Review.pdf & <STORE>_Action Plan.pdf, Î±Î»Î»Î¬ ÎºÎ±Î¹ ESC01_Review.pdf/ESC01_Plan.pdf, Î¼Îµ Î® Ï‡Ï‰ÏÎ¯Ï‚ Ï€Î±ÏÎ»ÎµÏ‚/ÎºÎµÎ½Î¬.")
uploaded = st.file_uploader("PDFs", type=["pdf"], accept_multiple_files=True)

st.markdown("### 2) Î”ÏÏƒÎµ Î»Î¯ÏƒÏ„Î± ÎºÎ±Ï„Î±ÏƒÏ„Î·Î¼Î¬Ï„Ï‰Î½")
store_list_text = st.text_area("STORE codes (Î­Î½Î± Î±Î½Î¬ Î³ÏÎ±Î¼Î¼Î®)", "ESC01\nLCI01\nLGS01\nLND01")

run = st.button("ğŸ”§ Parse & Generate")

if run:
    if not uploaded:
        st.error("Î‘Î½Î­Î²Î±ÏƒÎµ Ï€ÏÏÏ„Î± Ï„Î± PDFs.")
        st.stop()
    if not tpl_bex or not tpl_nonbex:
        st.error("Î‘Î½Î­Î²Î±ÏƒÎµ ÎºÎ±Î¹ Ï„Î± Î´ÏÎ¿ templates (.docx).")
        st.stop()
    if extract_text is None:
        st.error("Î›ÎµÎ¯Ï€ÎµÎ¹ pdfminer.six ÏƒÏ„Î¿ Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½.")
        st.stop()

    # index uploaded files
    pdf_map = {}
    unmatched = []
    for f in uploaded:
        store, role = parse_file_role(f.name)
        if not store or not role:
            unmatched.append(f.name)
            continue
        pdf_map.setdefault(store, {})[role] = f
    if unmatched:
        st.warning("ÎœÎ· Î±Î½Î±Î³Î½Ï‰ÏÎ¹ÏƒÎ¼Î­Î½Î± filenames: " + ", ".join(unmatched))

    # load templates
    tpl_bex_bytes = tpl_bex.read()
    tpl_nonbex_bytes = tpl_nonbex.read()

    # prepare zip
    out_zip = io.BytesIO()
    z = zipfile.ZipFile(out_zip, "w", zipfile.ZIP_DEFLATED)

    stores = [s.strip().upper() for s in store_list_text.splitlines() if s.strip()]
    built = 0

    for code in stores:
        cols = st.columns([1,2,2])
        cols[0].markdown(f"**{code}**")

        pair = pdf_map.get(code, {})
        rfile = pair.get("review")
        pfile = pair.get("plan")
        if not rfile or not pfile:
            cols[1].warning("Î›ÎµÎ¯Ï€ÎµÎ¹ Business Review Î® Action Plan PDF.")
            continue

        rbytes = rfile.read()
        pbytes = pfile.read()

        rtext = read_pdf_text_from_bytes(rbytes)
        ptext = read_pdf_text_from_bytes(pbytes)

        cols[1].write(f"Review text chars: {len(rtext)}")
        cols[2].write(f"Plan text chars: {len(ptext)}")

        if len(rtext) < 20 or len(ptext) < 20:
            cols[1].error("ÎˆÎ½Î± Î±Ï€ÏŒ Ï„Î± PDF Ï†Î±Î¯Î½ÎµÏ„Î±Î¹ ÏƒÎ±Î½ ÎµÎ¹ÎºÏŒÎ½Î± (Î´ÎµÎ½ Î­Ï‡ÎµÎ¹ ÎºÎµÎ¯Î¼ÎµÎ½Î¿). ÎšÎ¬Î½Îµ OCR (Recognize Text) ÎºÎ±Î¹ Î¾Î±Î½Î±Î´Î¿ÎºÎ¯Î¼Î±ÏƒÎµ.")
            continue

        rvals = parse_metrics(rtext, review_patterns)
        pvals = parse_metrics(ptext, plan_patterns)

        with st.expander(f"Diagnostics â€” {code}", expanded=False):
            st.write("Review extracted:", rvals)
            st.write("Plan extracted:", pvals)

        mapping = {}
        mapping.update({f"review_{k}": v for k, v in rvals.items()})
        mapping.update({f"plan_{k}": v for k, v in pvals.items()})
        mapping["store"] = code
        mapping["title"] = f"Review September 2025 â€” Plan October 2025 â€” {code}"

        # choose template
        is_bex = (code in bex_set)
        tpl_bytes = tpl_bex_bytes if is_bex else tpl_nonbex_bytes
        doc = Document(io.BytesIO(tpl_bytes))
        set_default_font(doc, "Aptos")
        replace_placeholders(doc, mapping)

        out_name = f"{code}_ReviewSep_PlanOct.docx"
        buf = io.BytesIO()
        doc.save(buf)
        z.writestr(out_name, buf.getvalue())
        built += 1

    z.close()
    if built == 0:
        st.error("Î”ÎµÎ½ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎµ Î±ÏÏ‡ÎµÎ¯Î¿. ÎˆÎ»ÎµÎ³Î¾Îµ filenames, ÏŒÏ„Î¹ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÎºÎ±Î¹ Ï„Î± 2 PDFs Î±Î½Î¬ store ÎºÎ±Î¹ ÏŒÏ„Î¹ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ ÏƒÎºÎ±Î½Î±ÏÎ¹ÏƒÎ¼Î­Î½ÎµÏ‚ ÎµÎ¹ÎºÏŒÎ½ÎµÏ‚.")
    else:
        st.success(f"ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ: Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎ±Î½ {built} Î±ÏÏ‡ÎµÎ¯Î±.")
        st.download_button("â¬‡ï¸ ÎšÎ±Ï„Î­Î²Î±ÏƒÎµ ÏŒÎ»Î± Ï„Î± .docx (ZIP)", data=out_zip.getvalue(), file_name="reviews_plan_docs.zip")
