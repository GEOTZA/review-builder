
import streamlit as st
import re, os, io, json, zipfile
from typing import Dict, Any, List, Tuple
from docx import Document
from docx.oxml.ns import qn

# PDF text extraction
try:
    from pdfminer.high_level import extract_text
except Exception as e:
    extract_text = None

st.set_page_config(page_title="Review/Plan Generator", layout="wide")

def set_default_font(doc, font_name="Aptos"):
    for style in doc.styles:
        if hasattr(style, "font"):
            try:
                style.font.name = font_name
                style._element.rPr.rFonts.set(qn('w:eastAsia'), font_name)
                style._element.rPr.rFonts.set(qn('w:cs'), font_name)
            except Exception:
                pass

def read_pdf_text(file_bytes: bytes) -> str:
    if extract_text is None:
        raise RuntimeError("pdfminer.six is not installed on this environment.")
    # pdfminer expects a file-like path or descriptor; wrap bytes in BytesIO and use extract_text
    bio = io.BytesIO(file_bytes)
    text = extract_text(bio) or ""
    return text

def parse_metrics(text: str, patterns: Dict[str, str]) -> Dict[str, Any]:
    results: Dict[str, Any] = {}
    for key, pat in patterns.items():
        try:
            m = re.search(pat, text, re.IGNORECASE | re.MULTILINE)
        except re.error as e:
            results[key] = f"[Regex error: {e}]"
            continue
        if m:
            # prefer the last capturing group if there are multiple
            group_val = None
            if m.lastindex and m.lastindex >= 1:
                group_val = m.group(m.lastindex)
            else:
                group_val = m.group(1) if len(m.groups()) >= 1 else m.group(0)
            val = (group_val or "").strip()
            val = val.replace(",", ".")
            # Try float cast but keep original if not numeric
            try:
                num = float(re.sub(r"[^0-9.\-]", "", val))
                results[key] = num
            except ValueError:
                results[key] = val
        else:
            results[key] = ""
    return results

def replace_placeholders(doc: Document, mapping: Dict[str, Any]):
    def repl_text(s: str) -> str:
        def rfun(m):
            k = m.group(1)
            return str(mapping.get(k, ""))
        return re.sub(r"\[\[([A-Za-z0-9_]+)\]\]", rfun, s)

    for p in doc.paragraphs:
        for r in p.runs:
            r.text = repl_text(r.text)

    for t in doc.tables:
        for row in t.rows:
            for cell in row.cells:
                for p in cell.paragraphs:
                    for r in p.runs:
                        r.text = repl_text(r.text)

st.title("ğŸ“„ Review/Plan Generator (BEX & Nonâ€‘BEX)")

with st.sidebar:
    st.header("âš™ï¸ Settings")
    st.caption("ÎŸÎ´Î®Î³Î·ÏƒÎµ Ï„Î¿ extraction Î¼Îµ BEX Î»Î¯ÏƒÏ„Î± ÎºÎ±Î¹ regex patterns.")
    bex_input = st.text_area("BEX stores (comma-separated)", "ESC01,FKM01,LND01,DRZ01,PKK01")
    bex_set = set([s.strip().upper() for s in bex_input.split(",") if s.strip()])

    default_review_patterns = {
        "mobile_actual": r"ÎšÎ¹Î½Î·Ï„(Î®|Î·Ï‚).*?(\d+)\s*(ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚|Î³ÏÎ±Î¼Î¼Î­Ï‚)",
        "fixed_actual":  r"Î£Ï„Î±Î¸ÎµÏ(Î®|Î®Ï‚).*?(\d+)\s*(ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚|Î³ÏÎ±Î¼Î¼Î­Ï‚)",
        "ftth_actual":   r"FTTH.*?(\d+)",
        "fwa_actual":    r"FWA.*?(\d+)",
        "eon_actual":    r"(EON|TV).*?(\d+)"
    }
    default_plan_patterns = {
        "mobile_target": r"(?i)ÎºÎ¹Î½Î·Ï„[Î®Î®Ï‚].*?(\d+)\s*(?:Î³Ï|lines|Î³ÏÎ±Ï†|ÎµÎ½ÎµÏÎ³)",
        "fixed_target":  r"(?i)ÏƒÏ„Î±Î¸ÎµÏ[Î®Î®Ï‚].*?(\d+)\s*(?:Î³Ï|lines|Î³ÏÎ±Ï†|ÎµÎ½ÎµÏÎ³)",
        "ftth_target":   r"(?i)ftth.*?(\d+)",
        "fwa_target":    r"(?i)fwa.*?(\d+)",
        "eon_target":    r"(?i)(eon|tv).*?(\d+)"
    }
    review_patterns_json = st.text_area("Review regex (JSON)", json.dumps(default_review_patterns, ensure_ascii=False, indent=2))
    plan_patterns_json   = st.text_area("Plan regex (JSON)", json.dumps(default_plan_patterns, ensure_ascii=False, indent=2))
    try:
        review_patterns = json.loads(review_patterns_json)
        plan_patterns = json.loads(plan_patterns_json)
    except Exception as e:
        st.error(f"JSON error: {e}")
        st.stop()

    st.markdown("---")
    st.subheader("ğŸ“„ Templates (.docx)")
    tpl_bex = st.file_uploader("BEX template", type=["docx"], key="tpl_bex")
    tpl_nonbex = st.file_uploader("Nonâ€‘BEX template", type=["docx"], key="tpl_nonbex")
    st.caption("Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ placeholders ÏŒÏ€Ï‰Ï‚ [[review_mobile_actual]], [[plan_mobile_target]], [[title]], [[store]].")

st.markdown("### 1) Î‘Î½Î­Î²Î±ÏƒÎµ Ï„Î± PDFs ÏƒÎ¿Ï…")
st.caption("ÎŸÎ½ÏŒÎ¼Î±ÏƒÎµ Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± Ï‰Ï‚ <STORE>_Review.pdf ÎºÎ±Î¹ <STORE>_Plan.pdf (Ï€.Ï‡. ESC01_Review.pdf, ESC01_Plan.pdf).")
uploaded = st.file_uploader("PDFs", type=["pdf"], accept_multiple_files=True)

st.markdown("### 2) Î”ÏÏƒÎµ Î»Î¯ÏƒÏ„Î± ÎºÎ±Ï„Î±ÏƒÏ„Î·Î¼Î¬Ï„Ï‰Î½")
store_list_text = st.text_area("STORE codes (Î­Î½Î± Î±Î½Î¬ Î³ÏÎ±Î¼Î¼Î®)", "ESC01\nPKK01")

run = st.button("ğŸ”§ Parse & Generate")

if run:
    if not uploaded:
        st.error("Î‘Î½Î­Î²Î±ÏƒÎµ Ï€ÏÏÏ„Î± Ï„Î± PDFs.")
        st.stop()
    if not tpl_bex or not tpl_nonbex:
        st.error("Î‘Î½Î­Î²Î±ÏƒÎµ ÎºÎ±Î¹ Ï„Î± Î´ÏÎ¿ templates (BEX & Nonâ€‘BEX).")
        st.stop()
    if extract_text is None:
        st.error("Î›ÎµÎ¯Ï€ÎµÎ¹ Î· Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ· pdfminer.six. Î¤ÏÎ­Î¾Îµ: pip install pdfminer.six")
        st.stop()

    # Index uploaded files by name
    pdf_map = {f.name: f for f in uploaded}
    stores = [s.strip().upper() for s in store_list_text.splitlines() if s.strip()]

    # Load templates in memory
    tpl_bex_bytes = tpl_bex.read()
    tpl_nonbex_bytes = tpl_nonbex.read()

    # Collect results to zip
    out_zip = io.BytesIO()
    z = zipfile.ZipFile(out_zip, mode="w", compression=zipfile.ZIP_DEFLATED)

    summary_rows: List[Tuple[str, Dict[str, Any], Dict[str, Any]]] = []

    for code in stores:
        r_name = f"{code}_Review.pdf"
        p_name = f"{code}_Plan.pdf"

        if r_name not in pdf_map or p_name not in pdf_map:
            st.warning(f"{code}: Î»ÎµÎ¯Ï€ÎµÎ¹ ÎºÎ¬Ï€Î¿Î¹Î¿ PDF ({r_name} Î® {p_name})")
            continue

        # Extract text
        review_text = read_pdf_text(pdf_map[r_name].read())
        plan_text   = read_pdf_text(pdf_map[p_name].read())

        # Parse metrics
        review_vals = parse_metrics(review_text, review_patterns)
        plan_vals   = parse_metrics(plan_text, plan_patterns)

        # Merge mapping
        mapping = {}
        mapping.update({f"review_{k}": v for k, v in review_vals.items()})
        mapping.update({f"plan_{k}": v for k, v in plan_vals.items()})
        mapping["store"] = code
        mapping["title"] = f"Review September 2025 â€” Plan October 2025 â€” {code}"

        # Choose template
        is_bex = (code in bex_set)
        tpl_bytes = tpl_bex_bytes if is_bex else tpl_nonbex_bytes
        # Build Word
        doc = Document(io.BytesIO(tpl_bytes))
        set_default_font(doc, "Aptos")
        replace_placeholders(doc, mapping)

        # Save to zip
        out_name = f"{code}_ReviewSep_PlanOct.docx"
        out_buf = io.BytesIO()
        doc.save(out_buf)
        z.writestr(out_name, out_buf.getvalue())

        summary_rows.append((code, review_vals, plan_vals))

    z.close()
    st.success("ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ Î· Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï„Ï‰Î½ Î±ÏÏ‡ÎµÎ¯Ï‰Î½.")
    st.download_button("â¬‡ï¸ ÎšÎ±Ï„Î­Î²Î±ÏƒÎµ ÏŒÎ»Î± Ï„Î± .docx (ZIP)", data=out_zip.getvalue(), file_name="reviews_plan_docs.zip")

    # Show a summary table
    if summary_rows:
        st.markdown("### Î£ÏÎ½Î¿ÏˆÎ· ÎµÎ¾Î±Î³ÏŒÎ¼ÎµÎ½Ï‰Î½ Ï„Î¹Î¼ÏÎ½")
        for code, r, p in summary_rows:
            with st.expander(code, expanded=False):
                st.write("**Review values**", r)
                st.write("**Plan values**", p)
